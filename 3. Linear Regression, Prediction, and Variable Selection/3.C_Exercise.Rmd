---
title: "LASSO Variable Selection"
output: 
  html_document: 
    theme: readable
    fig_caption: yes
    number_sections: yes
    toc: yes
  html_notebook: 
    fig_caption: yes
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---
# **Exercise:** 

> For a high dimensional dataset having n<p (n=200, p=500), is it possible to fit a linear regression on that directly?

```{r echo=TRUE, eval=FALSE}
HighDim <- read.csv(file = "https://xiaoruizhu.github.io/Data-Mining-R/lecture/data/HighDim.csv")
```
> Can we do subset variable selection? 
> How about LASSO variable selection?

```{r , eval=FALSE, echo=FALSE}
n <- 200;p <- 500;sigma <- 0.5
beta <- rep(0,p);nonzero <- c(1,2,3);zero <- setdiff(1:p,nonzero)
beta[nonzero] <- c(3,2,1.5)
Sigma <- 0.3^(abs(outer(1:p,1:p,"-")))

X <- mvrnorm(n,rep(0,p),Sigma)
error <- rnorm(n,0,sigma)
    
X <- apply(X,2,scale)*sqrt(n)/sqrt(n-1)
error <- error-mean(error)

Y <- X %*% beta + error
HighDim <- data.frame(Y, X)
head(HighDim)
HighDim <- HighDim[,-1]
write.csv(HighDim, file = "HighDim.csv")

test_lm <- lm(Y~., data = HighDim)
test_lm_null <- lm(Y ~ 1, data = HighDim)
summary(test_lm)
subset_result <- regsubsets(Y~.,data=HighDim, nbest=2, nvmax = 14)

model_step_b <- step(test_lm, direction='backward')
model_step_f <- step(test_lm_null, scope=list(lower=test_lm_null, upper=test_lm), direction='forward')
model_step_s <- step(nullmodel, scope=list(lower=nullmodel, upper=fullmodel), direction='both')
library(glmnet)
lasso_fit = glmnet(x = as.matrix(HighDim[,-1]), y = HighDim[,1], alpha = 1, intercept = FALSE)
summary(lasso_fit)
coef(lasso_fit, s = 0.5)

test_lm_3 <- lm(Y ~ X1+ X2+X3+0, data = HighDim)
summary(test_lm_3)
```

[go to top](#header)



