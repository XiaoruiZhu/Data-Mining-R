---
title: "Nonparametric Smoothing: Moving Beyond Linearity"
output: 
  html_document: 
    theme: readable
    fig_caption: yes
    number_sections: yes
    toc: yes
    code_folding: show
    df_print: paged
editor_options: 
  chunk_output_type: console
---


# **mcycle** motorcycle accident dataset

`mcycle` is a data frame giving a series of measurements of head acceleration in a simulated motorcycle accident, used to test crash helmets. It is an univariate case. We are interested in the relationship between the times in milliseconds after impact and the acceleration. 

```{r echo=TRUE, message = FALSE, results='hide'}
library(MASS)
data('mcycle')
str(mcycle)
summary(mcycle)
```

```{r echo=TRUE, message = FALSE}
# Rename the variables for ease of usage
Y <- mcycle$accel
X <- mcycle$times

#Scatterplot
plot(Y~X, xlab="time",ylab="Acceleration", main="Scatterplot of Acceleration against Time")
```


# Simple Linear Regression

We can simply assume a linear relationship and run a linear model between acceleration and time. 

```{r echo=TRUE, message = FALSE, results='hide'}
lm_mod <- lm(Y~X, data= mcycle)
summary(lm_mod)
```

**Fitted Regression Line**

But after we draw the fitted linear line on the scatterplot, we can clearly tell that the linear assumption seems violated. 

```{r echo=TRUE, message = FALSE}
plot(X, Y, xlab="Times", ylab="Acceleration", main="Simple Linear Regression Line")
abline(lm_mod, col="blue", lwd = 1)
```

# Polynomial Regression

If we assume there could be a polynomial relationship, we can try polynomial regression. The coefficients can be easily estimated using least squares linear regression because this is just a standard linear model with predictors $x, x^2, x^3, \dots, x^d$. 

## Quadratic

We can conduct a quadratic regression as follows by simply adding `I(X^2)` in the formula argument:
```{r echo=TRUE, message = FALSE}
quad_mod <- lm(Y~X+I(X^2), data=mcycle) 
summary(quad_mod)
```

It seems that the fitted line captures the curvature a little bit better than the linear regression. 

```{r echo=TRUE, message = FALSE}
plot(X ,Y ,xlab="Times", main = "Quadratic",ylab="Acceleration",cex=.5)
lines(X,quad_mod$fitted.values, col="blue", lwd = 1)
```

**Is this model superior to the simple linear regression model?** 

In order to answer this question, we can conduct the ANOVA test to compare the fits of these two models. 

```{r echo=TRUE, message = FALSE}
anova(lm_mod,quad_mod)
```



## Fifth-degree Polynomial

We can also try higher order polynomial regress, for example a fifth-degree polynomial.
```{r echo=TRUE, message = FALSE}
poly_mod <- lm(Y~poly(X,5,raw=T),data=mcycle) 
summary(poly_mod)
```

You can also assess the model performance.

```{r echo=TRUE, message = FALSE}
#poly_mod_summary <- summary(poly_mod)
#(poly_mod_summary$sigma)^2 
#poly_mod_summary$r.squared
#poly_mod_summary$adj.r.squared
#AIC(poly_mod)
#BIC(poly_mod)
```

```{r echo=TRUE, message = FALSE}
plot(X ,Y ,xlab="Times", main = "Fifth-degree polynomial",ylab="Acceleration",cex=.5)
lines(X,poly_mod$fitted.values, col="blue", lwd = 1)
```

This one may be even better to capture the curvature of samples on the left hand side of scatter plot than those two model above. 

[go to top](#header)

# Splines

## Regression Splines

In order to fit regression splines in R, we use the `bs()` function from the splines library. By default, "cubic splines" are produced. That is cubic polynomial with no interior knots

```{r echo=TRUE, message = FALSE, warning= FALSE}
library (splines)
reg_sp <- lm(Y~bs(X),data=mcycle)
summary(reg_sp)
```


```{r echo=TRUE, message = FALSE, warning= FALSE}
plot(X ,Y ,xlab="Times", main = "Regression Spline",ylab="Acceleration",cex=.5)
lines(X,reg_sp$fitted.values, col="blue", lwd = 1)

conf_interval <- predict(reg_sp, interval="confidence",
                         level = 0.95)
lines(X, conf_interval[,2], col="red", lty=2)
lines(X, conf_interval[,3], col="red", lty=2)
```


You can also specify the knot locations.

```{r echo=TRUE, message = FALSE, warning= FALSE}
#fit_sp=lm(Y~bs(X,knots=c(15.6,23.4,34.8)),data=mcycle) 
#summary(fit_sp)
#AIC(fit_sp)
```

You can also specify the degree of freedom.

```{r echo=TRUE, message = FALSE, warning= FALSE}
reg_sp2=lm(Y~bs(X,df=10),data=mcycle) 

plot(X ,Y ,xlab="Times", main = "Regression Spline with df=10",ylab="Acceleration",cex=.5)
lines(X,reg_sp2$fitted.values, col="blue", lwd = 1)

conf_interval <- predict(reg_sp2, interval="confidence",
                         level = 0.95)
lines(X, conf_interval[,2], col="red", lty=2)
lines(X, conf_interval[,3], col="red", lty=2)
```

## Natural Cubic Splines

Here the degree of freedom is pre-specified and different numbers are used to see the best curve that fits the data.

```{r echo=TRUE, message = FALSE, warning=FALSE}
#First: Natural Spline- pre-specified degree of freedom=4
fit2=lm(Y~ns(X,df=4),data=mcycle) 
plot(X ,Y,main= "Natural Cubic Spline with df=4", xlab="Times", ylab="Acceleration") 
lines(X, fit2$fitted.values)

conf_interval <- predict(fit2, interval="confidence",
                         level = 0.95)
lines(X, conf_interval[,2], col="red", lty=2)
lines(X, conf_interval[,3], col="red", lty=2)
```


```{r echo=TRUE, message = FALSE, warning=FALSE}
fit2c=lm(Y~ns(X,df=10),data=mcycle) 

plot(X ,Y , main= "Natural Cubic Spline with df=10", xlab="Times", ylab="Acceleration") 
lines(X, fit2c$fitted.values)

conf_interval <- predict(fit2c, interval="confidence",
                         level = 0.95)
lines(X, conf_interval[,2], col="red", lty=2)
lines(X, conf_interval[,3], col="red", lty=2)
```

```{r echo=TRUE, message = FALSE, warning=FALSE}
fit2d=lm(Y~ns(X,df=20),data=mcycle) 

plot(X ,Y, main= "Natural Cubic Spline with df=20", xlab="Times", ylab="Acceleration") 
lines(X, fit2d$fitted.values)

conf_interval <- predict(fit2d, interval="confidence",
                         level = 0.95)
lines(X, conf_interval[,2], col="red", lty=2)
lines(X, conf_interval[,3], col="red", lty=2)
```


## Smoothing/Penalized Spline

We now use penalized splines where a penalty/smoothing parameter can help control the smoothness while many knots can be used and knot location does not need to be carefully selected. The `s()` function is part of the gam function from the mgcv package.

[go to top](#header)
