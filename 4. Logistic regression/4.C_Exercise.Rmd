---
title: "Logistic Regression for Binary Classification"
output: 
  html_document: 
    theme: readable
    fig_caption: yes
    number_sections: yes
    toc: yes
  html_notebook: 
    fig_caption: yes
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---

# **Exercise:**

> 1. Based on a full model, create a confusion matrix when the cutoff probability equals to 0.1.

```{r echo=FALSE, eval=FALSE}
credit_data <- read.csv(file = "https://xiaoruizhu.github.io/Data-Mining-R/lecture/data/credit_default.csv", header=T)
library(dplyr)
credit_data<- rename(credit_data, default=default.payment.next.month)
credit_data$EDUCATION<- as.factor(credit_data$EDUCATION)
credit_data$MARRIAGE<- as.factor(credit_data$MARRIAGE)

index <- sample(nrow(credit_data),nrow(credit_data)*0.80)
credit_train = credit_data[index,]
credit_test = credit_data[-index,]

credit_glm0 <- glm(default~., family=binomial, data=credit_train)

pred_glm0_train <- predict(credit_glm0, type="response")

table(credit_train$default, (pred_glm0_train > 0.1)*1, dnn=c("Truth","Predicted"))
```

<!-- # **Exercise 1:**  -->

<!-- > 1. Change the weights to different values, and see how your optimal cut-off changes. -->
<!-- > 2. obtain confusion matrix and calculate the (asymmetric) cost based on the optimal cut-off.  -->
<!-- > 3. Find optimal cut-off probability using symmetric cost.  -->
<!-- > 4. Calculate MR and cost, what do you find? -->
<!-- > 5. Further, rewrite the cost function to make the weights (or the ratio of two weights) as input parameter. -->

<!-- # **Exercise 2:**  -->

<!-- > 1. Calculate MR, FPR, FNR based on the optimal cut-off you get from training sample with weights (5:1) -->
<!-- > 2. Calculate asymetric cost based on the optimal cut-off you get from training sample with weights (5:1) -->
<!-- > 3. Calculate above statistics based on the cut-off you get from training sample with symmetric weights (1:1)  -->

[go to top](#header)

